{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691c3465",
   "metadata": {},
   "source": [
    "A quick survey of some simple classifiers (LDA, QDA, logistic regression) and logistic regression with ridge shrinkage. Models are compared on original data, bootstrapped data, and oversampled data, and undersampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac30a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import sklearn.linear_model as skl\n",
    "import sklearn.model_selection as skm\n",
    "\n",
    "from ISLP import confusion_table\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89bbe032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(pathlib.Path.home(), \"stat5610\", \"stat-5610-project\", \"data\", \"train.csv\"))\n",
    "x_data = np.array(data[data.columns.drop(\"Y\")].values)\n",
    "y_data = data[\"Y\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58bc3c",
   "metadata": {},
   "source": [
    "Quantify imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5fe05ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 2.502%\n",
      "Negative: 97.498%\n"
     ]
    }
   ],
   "source": [
    "pos_count = sum(y_data == 1)\n",
    "neg_count = sum(y_data == 0)\n",
    "print(f\"Positive: {100*pos_count/len(y_data)}%\")\n",
    "print(f\"Negative: {100*neg_count/len(y_data)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ec244",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3fcbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(len(y_data)))\n",
    "train_idx, test_idx = skm.train_test_split(idx)\n",
    "x_train, y_train = x_data[train_idx, :], y_data[train_idx]\n",
    "x_test, y_test = x_data[test_idx, :], y_data[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae802472",
   "metadata": {},
   "source": [
    "Bootstrapped Class 1 observations for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_idx = np.where(y_train == 1)[0]\n",
    "class_0_idx = np.where(y_train == 0)[0]\n",
    "\n",
    "rng = np.random.default_rng(25)\n",
    "n = len(class_0_idx) # Bootstrap to get 50/50 split\n",
    "class_1_idx_bs = rng.choice(class_1_idx, n, replace=True)\n",
    "\n",
    "x_train_bs = np.concatenate([x_train[class_1_idx_bs], x_train[class_0_idx]])\n",
    "y_train_bs = np.concatenate([y_train[class_1_idx_bs], y_train[class_0_idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419a29d",
   "metadata": {},
   "source": [
    "Oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5838a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "x_train_sm, y_train_sm = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693ce9a",
   "metadata": {},
   "source": [
    "Undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f16d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "x_train_rus, y_train_rus = rus.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dea138",
   "metadata": {},
   "source": [
    "LDA classifier with bootstrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fba2d3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.1761723700887199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19244</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5128</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          19244   72\n",
       "1           5128  556"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA(store_covariance=True)\n",
    "results_lda = lda.fit(x_train_bs, y_train_bs)\n",
    "lda_pred = lda.predict(x_test)\n",
    "f1 = f1_score(y_test, lda_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "confusion_table(lda_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0e05d",
   "metadata": {},
   "source": [
    "LDA classifier with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89a376b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.1736757624398074\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19311</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5062</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          19311   86\n",
       "1           5062  541"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA(store_covariance=True)\n",
    "results_lda = lda.fit(x_train_sm, y_train_sm)\n",
    "lda_pred = lda.predict(x_test)\n",
    "f1 = f1_score(y_test, lda_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "confusion_table(lda_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f806547",
   "metadata": {},
   "source": [
    "LDA classifier with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "990b753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.17205671499123784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19263</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5110</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          19263   87\n",
       "1           5110  540"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA(store_covariance=True)\n",
    "results_lda = lda.fit(x_train_rus, y_train_rus)\n",
    "lda_pred = lda.predict(x_test)\n",
    "f1 = f1_score(y_test, lda_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "confusion_table(lda_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa2c7c",
   "metadata": {},
   "source": [
    "Logistic classifier with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2713b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.04945904173106646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24369</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          24369  611\n",
       "1              4   16"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.GLM(y_train, x_train, family=sm.families.Binomial())\n",
    "results = model.fit()\n",
    "\n",
    "preds = results.predict(x_test)\n",
    "\n",
    "n = len(preds)\n",
    "labels = np.zeros(n)\n",
    "labels[preds > 0.5] = 1\n",
    "f1 = f1_score(y_test, labels)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "conf_table_full = confusion_table(labels, y_test)\n",
    "conf_table_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c549dcb",
   "metadata": {},
   "source": [
    "Logistic classifier with bootstrapped Class 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5d123c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.20397208803005903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23327</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1045</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          23327  438\n",
       "1           1045  190"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.GLM(y_train_bs, x_train_bs, family=sm.families.Binomial())\n",
    "results = model.fit()\n",
    "\n",
    "preds = results.predict(x_test)\n",
    "\n",
    "n = len(preds)\n",
    "labels = np.zeros(n)\n",
    "labels[preds > 0.8] = 1\n",
    "f1 = f1_score(y_test, labels)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "conf_table_full = confusion_table(labels, y_test)\n",
    "conf_table_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b67a6c6",
   "metadata": {},
   "source": [
    "Logistic classifier with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b855490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.15636057287278854\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19529</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4844</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          19529  163\n",
       "1           4844  464"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.GLM(y_train_sm, x_train_sm, family=sm.families.Binomial())\n",
    "results = model.fit()\n",
    "\n",
    "preds = results.predict(x_test)\n",
    "\n",
    "n = len(preds)\n",
    "labels = np.zeros(n)\n",
    "labels[preds > 0.5] = 1\n",
    "f1 = f1_score(y_test, labels)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "conf_table_full = confusion_table(labels, y_test)\n",
    "conf_table_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2552b92",
   "metadata": {},
   "source": [
    "Logistic classifier with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f0ad21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.15523097826086957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19569</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4804</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          19569  170\n",
       "1           4804  457"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.GLM(y_train_rus, x_train_rus, family=sm.families.Binomial())\n",
    "results = model.fit()\n",
    "\n",
    "preds = results.predict(x_test)\n",
    "\n",
    "n = len(preds)\n",
    "labels = np.zeros(n)\n",
    "labels[preds > 0.5] = 1\n",
    "f1 = f1_score(y_test, labels)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "conf_table_full = confusion_table(labels, y_test)\n",
    "conf_table_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c789b",
   "metadata": {},
   "source": [
    "QDA classifier with bootstrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "323b25a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.24121679520137104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20895</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3477</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          20895   65\n",
       "1           3477  563"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(x_train_bs, y_train_bs)\n",
    "qda_pred = qda.predict(x_test)\n",
    "f1 = f1_score(y_test, qda_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "confusion_table(qda_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc57500",
   "metadata": {},
   "source": [
    "QDA classifier with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdd2fe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.262873957822462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21458</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2915</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          21458   91\n",
       "1           2915  536"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(x_train_sm, y_train_sm)\n",
    "qda_pred = qda.predict(x_test)\n",
    "f1 = f1_score(y_test, qda_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "confusion_table(qda_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45015d9",
   "metadata": {},
   "source": [
    "QDA classifier with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec1069bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.23711340206185566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20896</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3477</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth          0    1\n",
       "Predicted            \n",
       "0          20896   75\n",
       "1           3477  552"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(x_train_rus, y_train_rus)\n",
    "qda_pred = qda.predict(x_test)\n",
    "f1 = f1_score(y_test, qda_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "confusion_table(qda_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025aaf04",
   "metadata": {},
   "source": [
    "Regularized (ridge) logistic classifier with original data and CV to find l2 penalty weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7d6580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.21438263229308005\n"
     ]
    }
   ],
   "source": [
    "model = skl.LogisticRegression(penalty=\"l2\")\n",
    "parameters = {\"C\":list(np.arange(0.01,1.0, 0.05))}\n",
    "scorer = make_scorer(f1_score)\n",
    "clf = skm.GridSearchCV(model, parameters, scoring=scorer, return_train_score=True)\n",
    "result = clf.fit(x_train, y_train)\n",
    "preds = result.predict(x_test)\n",
    "f1 = f1_score(y_test, preds)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03560c3",
   "metadata": {},
   "source": [
    "Regularized (ridge) logistic classifier with bootstrapped data and CV to find l2 penalty weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9f4fb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.1864672116889894\n"
     ]
    }
   ],
   "source": [
    "model = skl.LogisticRegression(penalty=\"l2\")\n",
    "parameters = {\"C\":list(np.arange(0.01,10, 0.1))}\n",
    "scorer = make_scorer(f1_score)\n",
    "clf = skm.GridSearchCV(model, parameters, scoring=scorer, return_train_score=True)\n",
    "result = clf.fit(x_train_bs, y_train_bs)\n",
    "preds = result.predict(x_test)\n",
    "f1 = f1_score(y_test, preds)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d572d",
   "metadata": {},
   "source": [
    "Regularized (ridge) logistic classifier with oversampled data  and CV to find l2 penalty weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49d65648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.1901732060798869\n"
     ]
    }
   ],
   "source": [
    "model = skl.LogisticRegression(penalty=\"l2\")\n",
    "parameters = {\"C\":list(np.arange(0.01,1.0, 0.05))}\n",
    "scorer = make_scorer(f1_score)\n",
    "clf = skm.GridSearchCV(model, parameters, scoring=scorer, return_train_score=True)\n",
    "result = clf.fit(x_train_sm, y_train_sm)\n",
    "preds = result.predict(x_test)\n",
    "f1 = f1_score(y_test, preds)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d27974",
   "metadata": {},
   "source": [
    "Regularized (ridge) logistic classifier with undersampled data and CV to find l2 penalty weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b34b98ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.1833810888252149\n"
     ]
    }
   ],
   "source": [
    "model = skl.LogisticRegression(penalty=\"l2\")\n",
    "parameters = {\"C\":list(np.arange(0.01,1.0, 0.05))}\n",
    "scorer = make_scorer(f1_score)\n",
    "clf = skm.GridSearchCV(model, parameters, scoring=scorer, return_train_score=True)\n",
    "result = clf.fit(x_train_rus, y_train_rus)\n",
    "preds = result.predict(x_test)\n",
    "f1 = f1_score(y_test, preds)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
